{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/var/Sources/experiments/core/tts/Alternative', '/home/kaz/anaconda3/envs/core/lib/python37.zip', '/home/kaz/anaconda3/envs/core/lib/python3.7', '/home/kaz/anaconda3/envs/core/lib/python3.7/lib-dynload', '', '/home/kaz/.local/lib/python3.7/site-packages', '/home/kaz/anaconda3/envs/core/lib/python3.7/site-packages', '/home/kaz/anaconda3/envs/core/lib/python3.7/site-packages/Mako-1.0.7-py3.7.egg', '/home/kaz/anaconda3/envs/core/lib/python3.7/site-packages/IPython/extensions', '/home/kaz/.ipython', '../../']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('../../')\n",
    "print(sys.path)\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from mlutils.utils import plot, plots\n",
    "from models.mlmodeldic import best_model_path_and_settings\n",
    "import torch\n",
    "from tts.Alternative.neuravoice import Vocoder\n",
    "from tts.Alternative.train import train_vocoder\n",
    "from tts.Alternative.dataset import NeuraVoiceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'vocoder_{hidden_size}_{batch_size}_{lr}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeuraVoiceDataset(batch_size=batch_size)\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, collate_fn=dataset.mel_to_wav, drop_last=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path, settings = best_model_path_and_settings(model_name, 'loss_ave', is_lower_better=True)\n",
    "model_path, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f'cuda:{cuda}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_best_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 3.744 million\n"
     ]
    }
   ],
   "source": [
    "if model_path and use_best_model: model = Vocoder.init_from_settings(settings, model_path, device=device)\n",
    "else:                             model = Vocoder(hidden_size=hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/99 iter: 0/7614 total_iter: 100-- loss ave: 5.7100 loss: 5.30 -- elapse: 0m 44s speed 2.3 steps/sec\n",
      "epoch 0/99 iter: 0/7614 total_iter: 200-- loss ave: 4.5268 loss: 2.32 -- elapse: 1m 13s speed 2.7 steps/sec\n",
      "epoch 0/99 iter: 0/7614 total_iter: 300-- loss ave: 3.5327 loss: 1.21 -- elapse: 1m 41s speed 2.9 steps/sec\n",
      "epoch 0/99 iter: 0/7614 total_iter: 400-- loss ave: 2.8971 loss: 0.60 -- elapse: 2m 11s speed 3.1 steps/sec\n",
      "samples [[104 104 104 ...  85  85  85]\n",
      " [193 196 196 ... 107 170 107]\n",
      " [ 71  71 193 ...  57  53  51]\n",
      " ...\n",
      " [107  57  71 ... 170 170 170]\n",
      " [ 51  51  53 ... 107 107 107]\n",
      " [ 79  79 170 ... 193 193 193]]\n",
      "y [[ 95.  90.  85. ...  82.  80.  78.]\n",
      " [204. 203. 201. ... 157. 115. 121.]\n",
      " [ 76. 187. 186. ...  51.  46.  42.]\n",
      " ...\n",
      " [ 63.  78. 162. ... 153. 153. 154.]\n",
      " [ 52.  59.  69. ... 116. 110. 106.]\n",
      " [ 79. 174. 166. ... 191. 194. 198.]]\n",
      "loss 5.089479446411133\n",
      "epoch 0/99 iter: 16/7614 total_iter: 500-- loss ave: 5.1374 loss: 5.09 -- elapse: 2m 39s speed 3.1 steps/sec\n",
      "epoch 0/99 iter: 16/7614 total_iter: 600-- loss ave: 4.7209 loss: 4.32 -- elapse: 3m 8s speed 3.2 steps/sec\n",
      "epoch 0/99 iter: 16/7614 total_iter: 700-- loss ave: 3.8012 loss: 1.45 -- elapse: 3m 37s speed 3.2 steps/sec\n",
      "epoch 0/99 iter: 16/7614 total_iter: 800-- loss ave: 2.7664 loss: 0.58 -- elapse: 4m 5s speed 3.3 steps/sec\n",
      "epoch 0/99 iter: 16/7614 total_iter: 900-- loss ave: 2.1542 loss: 0.27 -- elapse: 4m 35s speed 3.3 steps/sec\n",
      "samples [[ 73  65  60 ... 104 145 186]\n",
      " [112 112 112 ... 123 104  73]\n",
      " [ 51  51  49 ... 145 145 145]\n",
      " ...\n",
      " [ 46  52  52 ... 196 196 175]\n",
      " [112 112 112 ... 145 145 145]\n",
      " [ 71  72  72 ...  46  46  46]]\n",
      "y [[ 66.  62.  58. ... 160. 187. 138.]\n",
      " [120. 124. 109. ...  93.  72.  63.]\n",
      " [ 50.  49.  51. ... 152. 152. 152.]\n",
      " ...\n",
      " [ 51.  52.  53. ... 195. 189. 183.]\n",
      " [117. 117. 116. ... 139. 139. 139.]\n",
      " [ 65.  64.  64. ...  45.  45.  43.]]\n",
      "loss 4.485393524169922\n",
      "epoch 0/99 iter: 32/7614 total_iter: 1000-- loss ave: 4.5703 loss: 4.49 -- elapse: 5m 4s speed 3.3 steps/sec\n",
      "model name:vocoder_512_16_0.0001 id:5cb057ca14468268b8c1cd22 saving path generated.\n",
      "best score. save model.\n",
      "trying to save model parameters odict_keys(['I.weight', 'I.bias', 'H1.weight_ih_l0', 'H1.weight_hh_l0', 'H1.bias_ih_l0', 'H1.bias_hh_l0', 'H2.weight_ih_l0', 'H2.weight_hh_l0', 'H2.bias_ih_l0', 'H2.bias_hh_l0', 'O1.weight', 'O1.bias', 'O2.weight', 'O2.bias']) to /diskB/6/out/models/vocoder/vocoder_512_16_0.0001_512_bit9_epoch100_lr0.0001_loss4-57_0 ..\n",
      "epoch 0/99 iter: 32/7614 total_iter: 1100-- loss ave: 4.0327 loss: 2.41 -- elapse: 5m 33s speed 3.3 steps/sec\n",
      "epoch 0/99 iter: 32/7614 total_iter: 1200-- loss ave: 2.8239 loss: 0.56 -- elapse: 6m 2s speed 3.3 steps/sec\n",
      "epoch 0/99 iter: 32/7614 total_iter: 1300-- loss ave: 2.1443 loss: 0.26 -- elapse: 6m 31s speed 3.3 steps/sec\n",
      "epoch 0/99 iter: 32/7614 total_iter: 1400-- loss ave: 1.7272 loss: 0.29 -- elapse: 7m 0s speed 3.3 steps/sec\n"
     ]
    }
   ],
   "source": [
    "losses, loss_aves, model = train_vocoder(\n",
    "    model, loader, lr=lr, model_name=model_name, n_epoch=100, seqlen=2500, device=device, verbose=False, check_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots([losses, loss_aves], labels=['losses', 'loss_aves'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
