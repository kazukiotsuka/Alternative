{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/var/Sources/experiments/core/tts/Alternative', '/home/kaz/anaconda3/envs/core/lib/python37.zip', '/home/kaz/anaconda3/envs/core/lib/python3.7', '/home/kaz/anaconda3/envs/core/lib/python3.7/lib-dynload', '', '/home/kaz/.local/lib/python3.7/site-packages', '/home/kaz/anaconda3/envs/core/lib/python3.7/site-packages', '/home/kaz/anaconda3/envs/core/lib/python3.7/site-packages/Mako-1.0.7-py3.7.egg', '/home/kaz/anaconda3/envs/core/lib/python3.7/site-packages/IPython/extensions', '/home/kaz/.ipython', '../../']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('../../')\n",
    "print(sys.path)\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from tools.libaudio.feature import melspectrogram\n",
    "from tools.libaudio.display import show_spec, show_mel\n",
    "from mlutils.utils import plot, plots, to_onehot\n",
    "from models.mlmodeldic import best_model_path_and_settings\n",
    "import torch\n",
    "from tts.Alternative.neuravoice import CharToMel\n",
    "from tts.Alternative.train import train_char2mel\n",
    "from tts.Alternative.dataset import NeuraVoiceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Sequence Generator with location-based Attention\n",
    "\n",
    "```\n",
    "x: input sequence\n",
    "y: mel spectrum sequence\n",
    "U: char length\n",
    "c: char sequence\n",
    "T: timestep length of input x\n",
    "wt: window vector into c at timestep t\n",
    "φ(t, u): window weight of cu at timestep t\n",
    "αt: parameters control the importance of the window within the mixture\n",
    "βt: parameters control the width of the window\n",
    "κt: parameters control the location of the window\n",
    "(eq.46): discrete convolution with a mixture of K Gaussian function\n",
    "\n",
    "xt ∈ R×R×{0,1}\n",
    "\n",
    "h1t = H(Wih1 xt + Wh1h1 h1t-1 + Wwh1 wt-1 + b1h)\n",
    "\n",
    "(αhat_t, βhat_t, khat_t) = Wh1p ht^1 + bp  # output of the first hidden layer\n",
    "\n",
    "αt = exp(αhat_t)  # importance of the window\n",
    "βt = exp(βhat_t)  # width of the window\n",
    "κt = κt-1 + exp(κhat_t)  # location of the window (how far to slide each window)\n",
    "\n",
    "φ(t, u) = Σk=1->K αkt*exp(-βkt(κkt-u)^2)  # mixture of K Gaussian\n",
    "\n",
    "\n",
    "cf. \n",
    "normal distribution\n",
    "N(X|μ,σ2) = 1/(2πσ2)^1/2 exp{-1/2σ2(x-μ)2}\n",
    "\n",
    "mixture gaussians\n",
    "p(x) = Σk=1->K πk N(X|μk,Σk)  # where πk:mixing coefficient, μk:mean, Σk:covariance, N(X|μk,Σk):mixture component\n",
    "p(x) = Σk=1->K πk (1/(2π)^D/2 1/|Σ|^1/2) exp{-1/2(x-μ)^T Σ^-1(x-μ)}  # where Σ:DxD dim covariance matrix, |Σ|:det Σ\n",
    "\n",
    "wt = Σu=1->U φ(t, u)*cu  # the soft window into c at timestep t\n",
    "\n",
    "hnt = H(Wihn xt + Whn-1hn hnt-1 + Whnhn hnt-1 + Wwhn wt + bnh)\n",
    "\n",
    "yˆtˆ = (eˆt,{wˆj_t,μˆJ_t,σˆj_t,ρˆj_t}^M_j=1) = by + Σn=1->N Whny hnt\n",
    "yt = Y(yˆt)\n",
    "\n",
    "et = 1 / (1 + exp(eˆt)) ⇒ et∈(0,1) : stroke probability\n",
    "πtj = exp(πtj) / (Σj't=1->M exp(πtj)) ⇒πtj∈(0,1), Σπtj=1 : mixture weights\n",
    "μjt = μˆjt ⇒ μjt∈R : means\n",
    "σtj = exp(σˆtj) ⇒ σˆtj > 0 : std\n",
    "pjt = tanh(pˆtj) ⇒ pˆtj∈(0,1) : correlations\n",
    "\n",
    "Pr(x|c) = ∏t=1->T Pr(xt+1|yt)\n",
    "L(x) = -log Pr(x|c)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver.1 hidden 256 out 256\n",
    "# ver.2 hidden 256 out 256 \n",
    "# ver.3 hidden 512 out 512, trainable init param\n",
    "# ver.4 hidden 512 out 512, trainable init param, batchnorm, relu\n",
    "# ver.5 hidden 512 out 512, trainable init param, batchnorm\n",
    "# ver.6 hidden 512 out 512, trainable init param, no encoder\n",
    "# ver.7 K=10, hidden 512 out 512, trainable init param, no encoder, use full gru\n",
    "# ver.9 fixed kappa_t_1 <- kappa_t feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 9\n",
    "batch_size = 16\n",
    "hidden_size = 512\n",
    "out_size = 512\n",
    "lr = 0.0001\n",
    "model_name = f'char2mel{hidden_size}_{out_size}_{batch_size}_ver{model_version}'\n",
    "cuda = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeuraVoiceDataset(batch_size=batch_size)\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, collate_fn=dataset.char_to_mel, drop_last=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path, settings = best_model_path_and_settings(model_name, 'loss_ave', is_lower_better=True)\n",
    "model_path, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f'cuda:{cuda}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_best_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version 9\n",
      "Trainable Parameters: 5.600 million\n"
     ]
    }
   ],
   "source": [
    "if model_path and use_best_model: model = CharToMel.init_from_settings(settings, model_path, device=device, **{'version': model_version})\n",
    "else:                             model = CharToMel(encode_type='onehot', K=10, hidden_size=512, out_size=512, version=model_version, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/99 iter: 1584/7614 total_iter: 100-- loss ave: 10.7123 loss: 7.97 -- elapse: 31m 26s speed 0.1 steps/sec\n",
      "epoch 0/99 iter: 3184/7614 total_iter: 200-- loss ave: 8.3348 loss: 4.10 -- elapse: 50m 19s speed 0.1 steps/sec\n",
      "epoch 0/99 iter: 4784/7614 total_iter: 300-- loss ave: 6.6716 loss: 3.46 -- elapse: 58m 42s speed 0.1 steps/sec\n",
      "epoch 0/99 iter: 6384/7614 total_iter: 400-- loss ave: 5.6017 loss: 2.02 -- elapse: 1h 6m 58s speed 0.1 steps/sec\n",
      "epoch 1/99 iter: 368/7614 total_iter: 500-- loss ave: 4.8374 loss: 2.14 -- elapse: 1h 15m 30s speed 0.1 steps/sec\n",
      "epoch 1/99 iter: 1968/7614 total_iter: 600-- loss ave: 4.2601 loss: 1.67 -- elapse: 1h 23m 36s speed 0.1 steps/sec\n",
      "epoch 1/99 iter: 3568/7614 total_iter: 700-- loss ave: 3.7986 loss: 0.62 -- elapse: 1h 32m 15s speed 0.1 steps/sec\n",
      "epoch 1/99 iter: 5168/7614 total_iter: 800-- loss ave: 3.4377 loss: 0.61 -- elapse: 1h 40m 18s speed 0.1 steps/sec\n",
      "epoch 1/99 iter: 6768/7614 total_iter: 900-- loss ave: 3.1494 loss: 0.73 -- elapse: 1h 48m 52s speed 0.1 steps/sec\n",
      "epoch 2/99 iter: 752/7614 total_iter: 1000-- loss ave: 2.9068 loss: 0.61 -- elapse: 1h 55m 50s speed 0.1 steps/sec\n",
      "model name:char2mel512_512_16_ver9 id:5cb12c8214468292910cf82d saving path generated.\n",
      "best score. save model.\n",
      "trying to save model parameters odict_keys(['h1_0', 'h2_0', 'h3_0', 'w_0', 'H1.weight_ih', 'H1.weight_hh', 'H1.bias_ih', 'H1.bias_hh', 'H2.weight_ih', 'H2.weight_hh', 'H2.bias_ih', 'H2.bias_hh', 'H3.weight_ih', 'H3.weight_hh', 'H3.bias_ih', 'H3.bias_hh', 'window.Wh1p.weight', 'window.Wh1p.bias', 'Wh1y.weight', 'Wh1y.bias', 'Wh2y.weight', 'Wh2y.bias', 'Wh3y.weight', 'Wh3y.bias', 'Y.weight', 'Y.bias']) to /diskB/6/out/models/char2mel/char2mel512_512_16_ver9_epoch100_lr0.0001_loss2-907_0 ..\n",
      "epoch 2/99 iter: 2352/7614 total_iter: 1100-- loss ave: 2.6996 loss: 0.50 -- elapse: 2h 1m 30s speed 0.2 steps/sec\n",
      "epoch 2/99 iter: 3952/7614 total_iter: 1200-- loss ave: 2.5206 loss: 0.31 -- elapse: 2h 7m 20s speed 0.2 steps/sec\n",
      "epoch 2/99 iter: 5552/7614 total_iter: 1300-- loss ave: 2.3662 loss: 0.67 -- elapse: 2h 13m 0s speed 0.2 steps/sec\n",
      "epoch 2/99 iter: 7152/7614 total_iter: 1400-- loss ave: 2.2286 loss: 0.69 -- elapse: 2h 18m 48s speed 0.2 steps/sec\n",
      "epoch 3/99 iter: 1136/7614 total_iter: 1500-- loss ave: 2.1083 loss: 0.88 -- elapse: 2h 24m 22s speed 0.2 steps/sec\n",
      "epoch 3/99 iter: 2736/7614 total_iter: 1600-- loss ave: 1.9991 loss: 0.35 -- elapse: 2h 30m 1s speed 0.2 steps/sec\n",
      "epoch 3/99 iter: 4336/7614 total_iter: 1700-- loss ave: 1.9035 loss: 0.15 -- elapse: 2h 35m 33s speed 0.2 steps/sec\n",
      "epoch 3/99 iter: 5936/7614 total_iter: 1800-- loss ave: 1.8166 loss: 0.29 -- elapse: 2h 41m 30s speed 0.2 steps/sec\n",
      "epoch 3/99 iter: 7536/7614 total_iter: 1900-- loss ave: 1.7405 loss: 0.23 -- elapse: 2h 47m 12s speed 0.2 steps/sec\n",
      "epoch 4/99 iter: 1520/7614 total_iter: 2000-- loss ave: 1.6683 loss: 0.25 -- elapse: 2h 53m 11s speed 0.2 steps/sec\n",
      "model name:char2mel512_512_16_ver9 id:5cb139f314468292910cf82e saving path generated.\n",
      "best score. save model.\n",
      "trying to save model parameters odict_keys(['h1_0', 'h2_0', 'h3_0', 'w_0', 'H1.weight_ih', 'H1.weight_hh', 'H1.bias_ih', 'H1.bias_hh', 'H2.weight_ih', 'H2.weight_hh', 'H2.bias_ih', 'H2.bias_hh', 'H3.weight_ih', 'H3.weight_hh', 'H3.bias_ih', 'H3.bias_hh', 'window.Wh1p.weight', 'window.Wh1p.bias', 'Wh1y.weight', 'Wh1y.bias', 'Wh2y.weight', 'Wh2y.bias', 'Wh3y.weight', 'Wh3y.bias', 'Y.weight', 'Y.bias']) to /diskB/6/out/models/char2mel/char2mel512_512_16_ver9_epoch100_lr0.0001_loss1-668_1 ..\n",
      "epoch 4/99 iter: 3120/7614 total_iter: 2100-- loss ave: 1.6031 loss: 0.22 -- elapse: 2h 59m 0s speed 0.2 steps/sec\n",
      "epoch 4/99 iter: 4720/7614 total_iter: 2200-- loss ave: 1.5418 loss: 0.39 -- elapse: 3h 5m 29s speed 0.2 steps/sec\n",
      "epoch 4/99 iter: 6320/7614 total_iter: 2300-- loss ave: 1.4853 loss: 0.20 -- elapse: 3h 23m 18s speed 0.2 steps/sec\n",
      "epoch 5/99 iter: 304/7614 total_iter: 2400-- loss ave: 1.4336 loss: 0.16 -- elapse: 3h 39m 35s speed 0.2 steps/sec\n",
      "epoch 5/99 iter: 1904/7614 total_iter: 2500-- loss ave: 1.3852 loss: 0.36 -- elapse: 3h 55m 47s speed 0.2 steps/sec\n",
      "epoch 5/99 iter: 3504/7614 total_iter: 2600-- loss ave: 1.3399 loss: 0.14 -- elapse: 4h 9m 22s speed 0.2 steps/sec\n",
      "epoch 5/99 iter: 5104/7614 total_iter: 2700-- loss ave: 1.2989 loss: 1.22 -- elapse: 4h 23m 5s speed 0.2 steps/sec\n",
      "epoch 5/99 iter: 6704/7614 total_iter: 2800-- loss ave: 1.2596 loss: 0.12 -- elapse: 4h 33m 56s speed 0.2 steps/sec\n",
      "epoch 6/99 iter: 688/7614 total_iter: 2900-- loss ave: 1.2228 loss: 0.17 -- elapse: 4h 43m 59s speed 0.2 steps/sec\n",
      "epoch 6/99 iter: 2288/7614 total_iter: 3000-- loss ave: 1.1887 loss: 1.08 -- elapse: 4h 52m 55s speed 0.2 steps/sec\n",
      "model name:char2mel512_512_16_ver9 id:5cb1560314468292910cf82f saving path generated.\n",
      "best score. save model.\n",
      "trying to save model parameters odict_keys(['h1_0', 'h2_0', 'h3_0', 'w_0', 'H1.weight_ih', 'H1.weight_hh', 'H1.bias_ih', 'H1.bias_hh', 'H2.weight_ih', 'H2.weight_hh', 'H2.bias_ih', 'H2.bias_hh', 'H3.weight_ih', 'H3.weight_hh', 'H3.bias_ih', 'H3.bias_hh', 'window.Wh1p.weight', 'window.Wh1p.bias', 'Wh1y.weight', 'Wh1y.bias', 'Wh2y.weight', 'Wh2y.bias', 'Wh3y.weight', 'Wh3y.bias', 'Y.weight', 'Y.bias']) to /diskB/6/out/models/char2mel/char2mel512_512_16_ver9_epoch100_lr0.0001_loss1-189_2 ..\n",
      "epoch 6/99 iter: 3888/7614 total_iter: 3100-- loss ave: 1.1563 loss: 0.32 -- elapse: 5h 1m 52s speed 0.2 steps/sec\n",
      "epoch 6/99 iter: 5488/7614 total_iter: 3200-- loss ave: 1.1259 loss: 0.16 -- elapse: 5h 11m 1s speed 0.2 steps/sec\n",
      "epoch 6/99 iter: 7088/7614 total_iter: 3300-- loss ave: 1.0965 loss: 0.07 -- elapse: 5h 20m 5s speed 0.2 steps/sec\n",
      "epoch 7/99 iter: 1072/7614 total_iter: 3400-- loss ave: 1.0687 loss: 0.25 -- elapse: 5h 29m 11s speed 0.2 steps/sec\n",
      "epoch 7/99 iter: 2672/7614 total_iter: 3500-- loss ave: 1.0430 loss: 0.06 -- elapse: 5h 37m 58s speed 0.2 steps/sec\n",
      "epoch 7/99 iter: 4272/7614 total_iter: 3600-- loss ave: 1.0182 loss: 0.06 -- elapse: 5h 47m 23s speed 0.2 steps/sec\n",
      "epoch 7/99 iter: 5872/7614 total_iter: 3700-- loss ave: 0.9945 loss: 0.22 -- elapse: 5h 54m 0s speed 0.2 steps/sec\n",
      "epoch 7/99 iter: 7472/7614 total_iter: 3800-- loss ave: 0.9722 loss: 0.07 -- elapse: 5h 59m 45s speed 0.2 steps/sec\n",
      "epoch 8/99 iter: 1456/7614 total_iter: 3900-- loss ave: 0.9508 loss: 0.10 -- elapse: 6h 5m 47s speed 0.2 steps/sec\n",
      "epoch 8/99 iter: 3056/7614 total_iter: 4000-- loss ave: 0.9304 loss: 0.25 -- elapse: 6h 11m 39s speed 0.2 steps/sec\n",
      "model name:char2mel512_512_16_ver9 id:5cb1687814468292910cf830 saving path generated.\n",
      "best score. save model.\n",
      "trying to save model parameters odict_keys(['h1_0', 'h2_0', 'h3_0', 'w_0', 'H1.weight_ih', 'H1.weight_hh', 'H1.bias_ih', 'H1.bias_hh', 'H2.weight_ih', 'H2.weight_hh', 'H2.bias_ih', 'H2.bias_hh', 'H3.weight_ih', 'H3.weight_hh', 'H3.bias_ih', 'H3.bias_hh', 'window.Wh1p.weight', 'window.Wh1p.bias', 'Wh1y.weight', 'Wh1y.bias', 'Wh2y.weight', 'Wh2y.bias', 'Wh3y.weight', 'Wh3y.bias', 'Y.weight', 'Y.bias']) to /diskB/6/out/models/char2mel/char2mel512_512_16_ver9_epoch100_lr0.0001_loss0-93_3 ..\n",
      "epoch 8/99 iter: 4656/7614 total_iter: 4100-- loss ave: 0.9110 loss: 0.18 -- elapse: 6h 17m 33s speed 0.2 steps/sec\n",
      "epoch 8/99 iter: 6256/7614 total_iter: 4200-- loss ave: 0.8925 loss: 0.17 -- elapse: 6h 23m 38s speed 0.2 steps/sec\n",
      "epoch 9/99 iter: 240/7614 total_iter: 4300-- loss ave: 0.8743 loss: 0.06 -- elapse: 6h 31m 28s speed 0.2 steps/sec\n",
      "epoch 9/99 iter: 1840/7614 total_iter: 4400-- loss ave: 0.8573 loss: 0.13 -- elapse: 6h 39m 47s speed 0.2 steps/sec\n"
     ]
    }
   ],
   "source": [
    "losses, loss_aves, model = train_char2mel(model, loader, n_epoch=1000, model_name=model_name, device=device, lr=lr, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(loss_aves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots([losses, loss_aves], labels=['losses', 'loss_aves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
